#!/usr/bin/env python3
"""
åˆ†æ PLM å…³é”®è¯åŒ¹é…è§„åˆ™çš„é€»è¾‘
é’ˆå¯¹è§„åˆ™ "é›¶ä»¶,part,component,ç»„ä»¶,éƒ¨ä»¶,æŸ¥æ‰¾,æœç´¢,æŸ¥è¯¢"
"""

import re
from typing import Dict, List, Tuple, Optional


class MockCategory:
    """æ¨¡æ‹Ÿåˆ†ç±»å¯¹è±¡"""
    def __init__(self, id: int, code: str):
        self.id = id
        self.code = code
        self.is_active = True


class MockRule:
    """æ¨¡æ‹Ÿè§„åˆ™å¯¹è±¡"""
    def __init__(self, id: int, category_id: int, content: str, weight: float = 1.0):
        self.id = id
        self.category_id = category_id
        self.content = content
        self.weight = weight
        self.rule_type = "keyword"
        self.is_active = True


def build_indices(rules: List[MockRule], categories: List[MockCategory]) -> Tuple[Dict[str, List[Tuple[MockCategory, MockRule]]], Dict[str, MockCategory]]:
    """
    æ„å»ºå…³é”®è¯ç´¢å¼•
    """
    keyword_index = {}
    exact_match_index = {}
    
    category_map = {c.id: c for c in categories}
    
    for rule in rules:
        if rule.rule_type != "keyword" or not rule.is_active:
            continue
        
        category = category_map.get(rule.category_id)
        if not category or not category.is_active:
            continue
        
        # æ ‡å‡†åŒ–å…³é”®è¯
        content = rule.content.strip().lower()
        
        # æ£€æŸ¥ç²¾ç¡®åŒ¹é…æ ‡è®°ï¼ˆä»¥ ^ å¼€å¤´ï¼‰
        if content.startswith("^"):
            exact_keyword = content[1:].strip()
            exact_match_index[exact_keyword] = category
        else:
            # å¤„ç†é€—å·åˆ†éš”çš„å¤šä¸ªå…³é”®è¯
            keywords = [k.strip() for k in content.split(",")]
            for keyword in keywords:
                if not keyword:
                    continue
                # æ·»åŠ åˆ°æ¨¡å¼ç´¢å¼•
                if keyword not in keyword_index:
                    keyword_index[keyword] = []
                
                keyword_index[keyword].append((category, rule))
    
    return keyword_index, exact_match_index

def calculate_confidence(text: str, keyword: str) -> float:
    """
    è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°
    """
    # å®Œå…¨åŒ¹é…
    if text == keyword:
        return 1.0
    
    # å¼€å¤´åŒ¹é…
    if text.startswith(keyword):
        bonus = 0.9
    # ç»“å°¾åŒ¹é…
    elif text.endswith(keyword):
        bonus = 0.85
    # æ£€æŸ¥å•è¯è¾¹ç•Œ
    elif f" {keyword} " in f" {text} " or f" {keyword}" in text:
        bonus = 0.8
    else:
        bonus = 0.6
    
    # é•¿åº¦æ¯”ç‡å¥–åŠ±ï¼ˆåå¥½æ›´é•¿çš„å…³é”®è¯ï¼‰
    length_ratio = len(keyword) / len(text)
    length_bonus = min(length_ratio * 0.2, 0.2)
    
    return min(bonus + length_bonus, 1.0)

def analyze_keyword_matching(rule_content: str, test_questions: List[str]):
    """
    åˆ†æå…³é”®è¯åŒ¹é…è§„åˆ™çš„é€»è¾‘
    """
    print(f"åˆ†æè§„åˆ™: {rule_content}")
    print("=" * 80)
    
    # åˆ›å»ºæ¨¡æ‹Ÿåˆ†ç±»å’Œè§„åˆ™
    category = MockCategory(1, "plm_assistant")
    rule = MockRule(1, 1, rule_content)
    
    # æ„å»ºç´¢å¼•
    keyword_index, exact_match_index = build_indices([rule], [category])
    
    # æ˜¾ç¤ºè§£æåçš„å…³é”®è¯
    print("è§£æåçš„å…³é”®è¯:")
    keywords = [k.strip() for k in rule_content.lower().split(",")]
    for i, keyword in enumerate(keywords, 1):
        print(f"  {i}. {keyword}")
    print()
    
    # æµ‹è¯•æ¯ä¸ªé—®é¢˜
    for question in test_questions:
        print(f"æµ‹è¯•é—®é¢˜: '{question}'")
        print("-" * 60)
        
        # æ ‡å‡†åŒ–é—®é¢˜
        text_normalized = question.strip().lower()
        
        # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
        if text_normalized in exact_match_index:
            print("  âœ… ç²¾ç¡®åŒ¹é…")
            print("  ç½®ä¿¡åº¦: 1.0")
            print(f"  åŒ¹é…ç±»åˆ«: {exact_match_index[text_normalized].code}")
        else:
            # æ£€æŸ¥éƒ¨åˆ†åŒ¹é…
            matches = []
            for keyword, entries in keyword_index.items():
                if keyword in text_normalized:
                    for category, rule in entries:
                        # è®¡ç®—ç½®ä¿¡åº¦
                        match_score = calculate_confidence(text_normalized, keyword)
                        confidence = match_score * rule.weight
                        matches.append({
                            "keyword": keyword,
                            "confidence": confidence,
                            "match_score": match_score,
                            "weight": rule.weight
                        })
            
            if matches:
                # æ˜¾ç¤ºæ‰€æœ‰åŒ¹é…
                print("  ğŸ” éƒ¨åˆ†åŒ¹é…ç»“æœ:")
                for match in matches:
                    print(f"    - å…³é”®è¯: '{match['keyword']}'")
                    print(f"      åŒ¹é…åˆ†æ•°: {match['match_score']:.2f}")
                    print(f"      æƒé‡: {match['weight']}")
                    print(f"      æœ€ç»ˆç½®ä¿¡åº¦: {match['confidence']:.2f}")
                
                # æ‰¾å‡ºæœ€ä½³åŒ¹é…
                best_match = max(matches, key=lambda m: m["confidence"])
                print(f"  ğŸ¯ æœ€ä½³åŒ¹é…: '{best_match['keyword']}'")
                print(f"     ç½®ä¿¡åº¦: {best_match['confidence']:.2f}")
                print(f"     åŒ¹é…ç±»åˆ«: {category.code}")
            else:
                print("  âŒ æ— åŒ¹é…")
        
        print()
    
    print("=" * 80)


if __name__ == "__main__":
    # æµ‹è¯•è§„åˆ™
    rule_content = "é›¶ä»¶,part,component,ç»„ä»¶,éƒ¨ä»¶,æŸ¥æ‰¾,æœç´¢,æŸ¥è¯¢"
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "æˆ‘æƒ³æŸ¥æ‰¾é›¶ä»¶",
        "å¸®æˆ‘æœç´¢component",
        "æŸ¥è¯¢éƒ¨ä»¶ä¿¡æ¯",
        "å¯»æ‰¾ç»„ä»¶",
        "partçš„è¯¦ç»†ä¿¡æ¯",
        "æˆ‘éœ€è¦å…³äºé›¶ä»¶çš„èµ„æ–™",
        "å¦‚ä½•æœç´¢éƒ¨ä»¶",
        "componentçš„è§„æ ¼æ˜¯ä»€ä¹ˆ",
        "æˆ‘æƒ³äº†è§£ç»„ä»¶çš„ä»·æ ¼",
        "æŸ¥è¯¢é›¶ä»¶åº“å­˜",
        "å¸®æˆ‘æ‰¾ä¸€ä¸‹part",
        "æœç´¢ç»„ä»¶çš„ä¾›åº”å•†",
        "æŸ¥è¯¢éƒ¨ä»¶çš„å¯ç”¨æ€§",
        "æˆ‘æƒ³è´­ä¹°é›¶ä»¶",
        "componentçš„æ›¿ä»£å“æœ‰å“ªäº›",
        "å¦‚ä½•æŸ¥æ‰¾ç»„ä»¶",
        "éƒ¨ä»¶çš„ä¿ä¿®æœŸæ˜¯å¤šä¹…",
        "æœç´¢é›¶ä»¶çš„æŠ€æœ¯æ–‡æ¡£",
        "æŸ¥è¯¢componentçš„äº¤ä»˜æ—¶é—´",
        "å¸®æˆ‘æ‰¾ç»„ä»¶çš„å›¾çº¸"
    ]
    
    analyze_keyword_matching(rule_content, test_questions)
